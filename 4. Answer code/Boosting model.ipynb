{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import xgboost\n",
    "from xgboost import plot_importance\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoding을 적용하는 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_encoding(df):\n",
    "    le = LabelEncoder()\n",
    "    original_columns = list(df.columns)\n",
    "    \n",
    "    for col in df:\n",
    "        # df의 컬럼의 유형이 object인 것들만\n",
    "        if df[col].dtype == 'object':\n",
    "            le.fit(df[col])\n",
    "            df[col] = le.transform(df[col])\n",
    "\n",
    "    # 새롭게 만들어진 컬럼들의 이름을 리스트로 저장\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    \n",
    "    # 수치형으로 변경된 df와 새롭게 만들어진 컬럼 이름 리스트를 반환\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "train = pd.read_csv(path + 'train.csv', index_col=0)\n",
    "test = pd.read_csv(path + 'test_x.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### label 값의 2를 0으로 변경해 주었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['voted'] = 2 - train['voted']\n",
    "# train['voted'].replace(2, 0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Cleansing & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding의 경우 xgbclassifier 모델을 학습시키기 위한 데이터에만 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train.append(test)\n",
    "\n",
    "df = pd.get_dummies(df, columns=['religion', 'race'], dummy_na=False) # one-hot-encoding\n",
    "\n",
    "df, df_new_columns = label_encoding(df)\n",
    "\n",
    "df = df[df['familysize'] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qe_columns = [i for i in df.columns[range(1, 40, 2)]]\n",
    "\n",
    "df['qe_median'] = df[qe_columns].median(axis=1)\n",
    "\n",
    "df[qe_columns] = np.log1p(df[qe_columns])\n",
    "\n",
    "df['qe_logsum'] = df[qe_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_qe_label(df):\n",
    "    if df < 100: return 1\n",
    "    elif df < 150: return 2\n",
    "    else: return 0\n",
    "    \n",
    "df['qe_logsum_label'] = df['qe_logsum'].apply(lambda x:get_sum_qe_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def familysize_label(df):\n",
    "    if df < 4: return 1\n",
    "    elif df < 8: return 2\n",
    "    elif df < 16: return 3\n",
    "    elif df < 32: return 4\n",
    "    else: return 0\n",
    "  \n",
    "df['familysize_label'] = df['familysize'].apply(lambda x:familysize_label(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_minus = ['e', 'f', 'k', 'q', 'r', 'a', 'd', 'g', 'i', 'n']\n",
    "\n",
    "for i in ls_minus:\n",
    "    df[f'Q{i}A'] = 6 - df[f'Q{i}A']\n",
    "    \n",
    "qa_columns = [i for i in df.columns[range(0, 39, 2)]]\n",
    "\n",
    "df['mach_score'] = df[qa_columns].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_ls = ['QqA', 'QeA', 'QbA', 'QhA', 'QjA', 'QmA']\n",
    "tactics_ls = ['QcA', 'QfA', 'QoA', 'QsA', 'QrA']\n",
    "\n",
    "df['views_score'] = df[views_ls].sum(axis=1)\n",
    "df['tactics_score'] = df[tactics_ls].sum(axis=1) # catboost에서는 제외"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tp06'] = 8 - df['tp06']\n",
    "df['tp02'] = 8 - df['tp02']\n",
    "df['tp08'] = 8 - df['tp08']\n",
    "df['tp04'] = 8 - df['tp04']\n",
    "df['tp10'] = 8 - df['tp10']\n",
    "\n",
    "df['extreversion_score'] = df['tp01'] + df['tp06'] # catboost에서는 제외\n",
    "df['agreeableness_score'] = df['tp07'] + df['tp02'] \n",
    "df['conscientiousness_score'] = df['tp03'] + df['tp08'] # catboost에서는 제외\n",
    "df['emotionalstability_score'] = df['tp09'] + df['tp04'] # catboost에서는 제외\n",
    "df['opennessexperiences_score'] = df['tp05'] + df['tp10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrs = [f for f in df.columns if 'wr' in f]\n",
    "wfs = [f for f in df.columns if 'wf' in f]\n",
    "\n",
    "df['wrs_count'] = df[wrs].sum(axis=1) \n",
    "df['wfs_count'] = df[wfs].sum(axis=1) # catboost에서는 제외\n",
    "\n",
    "df['wrs_kurt'] = df[wrs].kurtosis(axis=1) # catboost에서는 제외\n",
    "df['wrs_skew'] = df[wrs].skew(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age_group'].replace(0, 7, inplace=True)\n",
    "df['education'].replace(0, 5, inplace=True)\n",
    "\n",
    "df['n2_prod'] = df['age_group'] * df['education']\n",
    "df['n2_prod_weighted'] = df['age_group'] * 0.52 + df['education'] * 0.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_list = ['QaE', 'QbE', 'QcE', 'QdE', 'QeE',\n",
    "             'QfE', 'QgE', 'QhE', 'QiE', 'QjE',\n",
    "             'QkE', 'QlE', 'QmE', 'QnE', 'QoE',\n",
    "             'QpE', 'QqE', 'QrE', 'QsE', 'QtE', \n",
    "             'hand']\n",
    "\n",
    "df = df.drop(drop_list, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBClassifier Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =  {'colsample_bylevel': 0.92859, 'colsample_bytree': 0.55352, 'eta': 0.015, 'gamma': 0.62587, 'min_child_weight': 48.0, 'reg_alpha': 0.54, 'reg_lambda': 1.062, 'subsample': 0.89}\n",
    "\n",
    "params['min_child_weight'] = int(params['min_child_weight'])\n",
    "\n",
    "clf = XGBClassifier(\n",
    "             **params,\n",
    "             max_depth=11,\n",
    "             booster='gbtree',\n",
    "             n_estimators=5000,\n",
    "             objective= 'binary:logistic',\n",
    "             eval_metric='auc',\n",
    "             n_jobs= -1,\n",
    "             scale_pos_weight= 1.206,\n",
    "             random_state= 55 \n",
    ")\n",
    "\n",
    "train = df[df['voted'].notnull()]\n",
    "test = df[df['voted'].isnull()]\n",
    "\n",
    "train = train.astype({'voted':'int'})\n",
    "test = test.drop(columns = ['voted'])\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=55)\n",
    "feats = [f for f in train.columns if f not in ['voted']]\n",
    "\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "xgb_sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train[feats], train['voted'])):\n",
    "    train_x, train_y = train[feats].iloc[train_idx], train['voted'].iloc[train_idx]\n",
    "    valid_x, valid_y = train[feats].iloc[valid_idx], train['voted'].iloc[valid_idx]\n",
    "    \n",
    "    clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)],\n",
    "        eval_metric='auc', verbose=False, early_stopping_rounds=500)\n",
    "    \n",
    "    oof_preds[valid_idx] = clf.predict_proba(valid_x, ntree_limit=clf.best_ntree_limit)[:, 1]\n",
    "    xgb_sub_preds += (1 - clf.predict_proba(test, ntree_limit=clf.best_ntree_limit)[:, 1]) / folds.n_splits\n",
    "\n",
    "#     print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "# print('Full AUC score %.6f' % roc_auc_score(train['voted'], oof_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMClassifier Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'colsample_bytree': 0.675479, 'learning_rate': 0.00645, 'max_depth': 10.3, 'min_child_samples': 88.41, 'min_child_weight': 28.4, 'min_split_gain': 0.025029, 'num_leaves': 86.2, 'reg_alpha': 0.544736, 'reg_lambda': 0.15015, 'subsample': 0.7295}\n",
    "\n",
    "params['num_leaves'] = int(params['num_leaves'])\n",
    "params['max_depth'] = int(params['max_depth'])\n",
    "params['min_child_samples'] = int(params['min_child_samples'])\n",
    "\n",
    "clf = LGBMClassifier(\n",
    "        **params,\n",
    "        objective= 'binary',\n",
    "        subsample_for_bin= 240000,\n",
    "        is_unbalance= False,\n",
    "        n_estimators=10000,\n",
    "        n_jobs=-1,\n",
    "        silent= -1,\n",
    "        verbose= -1,\n",
    "        random_state=55     \n",
    ")\n",
    "\n",
    "train = df[df['voted'].notnull()]\n",
    "test = df[df['voted'].isnull()]\n",
    "\n",
    "train = train.astype({'voted':'int'})\n",
    "test = test.drop(columns = ['voted'])\n",
    "\n",
    "cat_feature = ['education', 'engnat', 'married', 'urban', 'age_group', 'gender', 'race', 'religion']\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=55)\n",
    "feats = [f for f in train.columns if f not in ['voted']]\n",
    "\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "lgbm_sub_preds = np.zeros(test.shape[0])\n",
    "\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train[feats], train['voted'])):\n",
    "    train_x, train_y = train[feats].iloc[train_idx], train['voted'].iloc[train_idx]\n",
    "    valid_x, valid_y = train[feats].iloc[valid_idx], train['voted'].iloc[valid_idx]\n",
    "    \n",
    "    clf.fit(train_x, train_y, eval_set = [(train_x, train_y), (valid_x, valid_y)],\n",
    "        eval_metric='auc', verbose=False, early_stopping_rounds=800,\n",
    "        feature_name= list(train[feats].columns), categorical_feature= cat_feature)\n",
    "    \n",
    "    oof_preds[valid_idx] = clf.predict_proba(valid_x, num_iteration=clf.best_iteration_)[:, 1]\n",
    "    lgbm_sub_preds += clf.predict_proba(test, num_iteration=clf.best_iteration_)[:, 1] / folds.n_split\n",
    "\n",
    "#     print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "# print('Full AUC score %.6f' % roc_auc_score(train['voted'], oof_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboostclassifier Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df['voted'].notnull()]\n",
    "test = df[df['voted'].isnull()]\n",
    "\n",
    "train = train.astype({'voted':'int'})\n",
    "test = test.drop(columns = ['voted'])\n",
    "\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=55)\n",
    "feats = [f for f in train.columns if f not in ['voted']]\n",
    "\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "cat_preds = np.zeros(test.shape[0])\n",
    "\n",
    "cat_feature = ['education', 'engnat', 'married', 'urban', 'age_group', 'gender', 'race', 'religion']\n",
    "\n",
    "params = {'bagging_temperature': 0.375906,\n",
    "  'depth': 9.0,\n",
    "  'l2_leaf_reg': 68.8,\n",
    "  'learning_rate': 0.011,\n",
    "  'od_wait': 138.699,\n",
    "  'subsample': 0.76046}\n",
    "\n",
    "params['depth'] = int(params['depth'])\n",
    "params['l2_leaf_reg'] = int(params['l2_leaf_reg'])\n",
    "params['od_wait'] = int(params['od_wait'])\n",
    "\n",
    "clf = CatBoostClassifier(\n",
    "                          **params,\n",
    "                          iterations=5000,\n",
    "                          eval_metric='AUC',\n",
    "                          allow_writing_files=False,\n",
    "                          od_type='Iter',\n",
    "                          random_state=55)\n",
    "    \n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train[feats], train['voted'])):\n",
    "    train_x, train_y = train[feats].iloc[train_idx], train['voted'].iloc[train_idx]\n",
    "    valid_x, valid_y = train[feats].iloc[valid_idx], train['voted'].iloc[valid_idx]\n",
    "    \n",
    "    clf.fit(train_x, train_y, \n",
    "            eval_set=[(train_x, train_y), (valid_x, valid_y)],\n",
    "            verbose=False, early_stopping_rounds=500,\n",
    "            use_best_model=True, \n",
    "            cat_features=cat_feature)\n",
    "    \n",
    "    oof_preds[valid_idx] = clf.predict_proba(valid_x)[:, 1]\n",
    "    cat_sub_preds += clf.predict_proba(test)[:, 1] / folds.n_splits\n",
    "    \n",
    "#     print('Fold %2d AUC : %.6f' % (n_fold + 1, roc_auc_score(valid_y, oof_preds[valid_idx])))\n",
    "    \n",
    "# print('Full AUC score %.6f' % roc_auc_score(train['voted'], oof_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Create Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_sub_preds = (cat_sub_preds * 0.55) + (xgb_sub_preds * 0.37) + (lgbm_sub_preds * 0.08)\n",
    "\n",
    "submit = pd.read_csv(path + 'sample_submission.csv', index_col = 0)\n",
    "\n",
    "submit['voted'] = ensemble_sub_preds\n",
    "submit.to_csv('ensemble.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
